{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGGAN CelebA\n",
    "\n",
    "This notebook is for implementing `Progressive Growing Generative Adversarial Network(PGGAN)` from the paper [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196) with [Tensorflow](https://www.tensorflow.org). <br>\n",
    "[CelebA dataset](https://www.kaggle.com/jessicali9530/celeba-dataset), which is 128x128 size, will be used. \n",
    "\n",
    "Reference: [hwalsuklee's Github](https://github.com/hwalsuklee/tensorflow-generative-model-collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import cv2 \n",
    "import datetime\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'PGGAN_CelebA'\n",
    "\n",
    "img_size = 128\n",
    "\n",
    "n_latent = 100\n",
    "\n",
    "beta1 = 0\n",
    "beta2 = 0.9\n",
    "\n",
    "learning_rate_g = 0.00015\n",
    "learning_rate_d = 0.0001\n",
    "\n",
    "show_result_step = 1000\n",
    "\n",
    "batch_list = [128, 128, 64, 64, 32, 16]\n",
    "epoch_list = [3, 3, 5, 6, 8, 10]\n",
    "size_list = [4, 8, 16, 32, 64, 128]\n",
    "channel_list = [64, 128, 256, 512, 512, 512]\n",
    "\n",
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d-%H-%M-%S\")\n",
    "\n",
    "start_level = 0\n",
    "\n",
    "load_model = False\n",
    "train_model = True\n",
    "\n",
    "save_path = \"./saved_models/\" + date_time + \"_\" + algorithm\n",
    "load_path = \"./saved_models/20191029-01-06-33_PGGAN_CelebA/32/model\" \n",
    "\n",
    "# WGAN_GP Parateter\n",
    "n_critic = 1\n",
    "d_lambda = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CelebA Dataset\n",
    "\n",
    "Get names of the files in the celeba dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebA_list = glob.glob('./img_align_celeba/*.jpg')\n",
    "\n",
    "print(\"CelebA dataset Length: {}\".format(len(celebA_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGGAN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGGAN():\n",
    "    def __init__(self, stage):\n",
    "        self.stage = stage\n",
    "        self.channel_list = channel_list\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, size_list[stage], size_list[stage], 3], name='x_'+str(stage))\n",
    "        self.x_normalize = (tf.cast(self.x, tf.float32) - (1.0/2)) / (1.0/2)\n",
    "\n",
    "        self.z = tf.placeholder(tf.float32, shape=[None, n_latent], name='z_'+str(stage))\n",
    "        \n",
    "        self.alpha = tf.placeholder(tf.float32, shape=[1])\n",
    "        self.batch_size = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.d_loss, self.g_loss, self.G = self.GAN(self.x_normalize, self.z) \n",
    "\n",
    "        # optimization\n",
    "        self.trainable_vars = tf.trainable_variables()\n",
    "\n",
    "        self.trainable_vars_d = [var for var in self.trainable_vars if var.name.startswith('Discriminator' + str(self.stage))]\n",
    "        self.trainable_vars_g = [var for var in self.trainable_vars if var.name.startswith('Generator' + str(self.stage))]\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer_d = tf.train.AdamOptimizer(learning_rate_d, beta1, beta2)\n",
    "            gvs_d = optimizer_d.compute_gradients(self.d_loss, var_list=self.trainable_vars_d)\n",
    "            capped_gvs_d = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs_d]\n",
    "            self.train_step_d = optimizer_d.apply_gradients(capped_gvs_d)\n",
    "            \n",
    "            optimizer_g = tf.train.AdamOptimizer(learning_rate_g, beta1, beta2)\n",
    "            gvs_g = optimizer_g.compute_gradients(self.g_loss, var_list=self.trainable_vars_g)\n",
    "            capped_gvs_g = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs_g]\n",
    "            self.train_step_g = optimizer_g.apply_gradients(capped_gvs_g)\n",
    "\n",
    "    def GAN(self, x, z):\n",
    "        # Generator\n",
    "        G, mini_std = self.Generator(z)\n",
    "\n",
    "        # Discriminator\n",
    "        D_logit_real, D_out_real = self.Discriminator(x, mini_std)\n",
    "        D_logit_fake, D_out_fake = self.Discriminator(G, mini_std, reuse=True)\n",
    "    \n",
    "        # get loss (LSGAN)\n",
    "        ########################################### LSGAN ###########################################\n",
    "        d_loss = tf.reduce_mean(tf.square(D_logit_real-1)) + tf.reduce_mean(tf.square(D_logit_fake))\n",
    "        g_loss = tf.reduce_mean(tf.square(D_logit_fake-1))\n",
    "        #############################################################################################\n",
    "        \n",
    "        return d_loss, g_loss , G\n",
    "    \n",
    "    # Pixel Normalization\n",
    "    def pixel_norm(self, x, epsilon=1e-8):\n",
    "        return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + epsilon)\n",
    "    \n",
    "    # Minibatch Standard Deviation\n",
    "    def minibatch_std(self, x):\n",
    "        # Compute Standard Deviation over minibatch\n",
    "        _, batch_std = tf.nn.moments(x, axes=[0], keep_dims=True)\n",
    "        \n",
    "        # Average all features\n",
    "        feature_avg = tf.reduce_mean(batch_std, axis=-1, keepdims=True)\n",
    "        \n",
    "        # Replicate the value to concatenate it over the minibatch\n",
    "        out = tf.tile(feature_avg, multiples=[self.batch_size, 1, 1, 1])\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def conv_block_g(self, x, num_channel, network_name):        \n",
    "        h1 = tf.layers.conv2d(x, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_1')\n",
    "        h1 = tf.nn.leaky_relu(self.pixel_norm(h1))  \n",
    "            \n",
    "        h2 = tf.layers.conv2d(h1, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_2')\n",
    "        h2 = tf.nn.leaky_relu(self.pixel_norm(h2))  \n",
    "        \n",
    "        return h2\n",
    "\n",
    "    \n",
    "    def conv_block_d(self, x, num_channel, network_name):\n",
    "        h1 = tf.layers.conv2d(x, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_1')\n",
    "        h1 = tf.nn.leaky_relu(h1)\n",
    "        \n",
    "        h2 = tf.layers.conv2d(h1, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_2')\n",
    "        h2 = tf.nn.leaky_relu(h2)\n",
    "\n",
    "        return h2\n",
    "\n",
    "    def Generator(self, x, reuse=False):\n",
    "        with tf.variable_scope('Generator' + str(self.stage), reuse=reuse):       \n",
    "            # Project and Reshape \n",
    "            z_size = int(size_list[0]/4)\n",
    "            \n",
    "            x_project = tf.layers.dense(x, z_size*z_size*n_latent)\n",
    "            x_reshape = tf.reshape(x_project, (-1, z_size, z_size, n_latent))\n",
    "            \n",
    "            h1 = tf.layers.conv2d_transpose(x_reshape,filters=channel_list[-1], kernel_size=4, strides=4, padding='SAME')\n",
    "            h1 = tf.nn.leaky_relu(self.pixel_norm(h1))\n",
    "            \n",
    "            h2 = tf.layers.conv2d(h1,filters=channel_list[-1], kernel_size=3, strides=1, padding='SAME')\n",
    "            h2 = tf.nn.leaky_relu(self.pixel_norm(h2))  \n",
    "\n",
    "            mini_std = self.minibatch_std(h2)\n",
    "        \n",
    "            in_block = h2\n",
    "            out_block = h2\n",
    "            upsample = h2\n",
    "\n",
    "            for i in range(self.stage):\n",
    "                upsample = tf.image.resize_nearest_neighbor(in_block, (size_list[i+1], size_list[i+1]))\n",
    "                out_block = self.conv_block_g(upsample, channel_list[-2-i], 'block'+str(i))\n",
    "                in_block = out_block\n",
    "\n",
    "            # Output layer           \n",
    "            RGB1 = tf.layers.conv2d(upsample, filters=3, kernel_size=1, strides=1, padding='SAME', name='RGB1_'+str(self.stage)) \n",
    "            RGB2 = tf.layers.conv2d(out_block, filters=3, kernel_size=1, strides=1, padding='SAME', name='RGB2_'+str(self.stage)) \n",
    "            \n",
    "            logits = (1-self.alpha)*RGB1 + self.alpha*RGB2\n",
    "            \n",
    "            output = tf.tanh(logits)\n",
    "        \n",
    "        return output, mini_std      \n",
    "\n",
    "\n",
    "    def Discriminator(self, x, mini_std, reuse=False):\n",
    "        with tf.variable_scope('Discriminator' + str(self.stage), reuse=reuse):\n",
    "            \n",
    "            h1 = tf.layers.conv2d(x, filters=channel_list[-self.stage-1], kernel_size=1, strides=1, activation=tf.nn.leaky_relu, \n",
    "                      padding='SAME', name='h1_'+str(self.stage))\n",
    "                \n",
    "            in_block = h1\n",
    "            out_block = h1\n",
    "            \n",
    "            for i in range(self.stage):\n",
    "                out_block = self.conv_block_d(in_block, channel_list[-self.stage+i], 'block'+str(self.stage-1-i))\n",
    "                \n",
    "                if i == 0:\n",
    "                    out_downsample = tf.layers.average_pooling2d(out_block, 2, 2)\n",
    "                    in_downsample = tf.layers.average_pooling2d(in_block, 2, 2)\n",
    "                    in_feature = tf.layers.conv2d(in_downsample, filters=out_downsample.get_shape()[3], \n",
    "                                                  kernel_size=1, strides=1, padding='SAME', name='feature_'+str(self.stage))\n",
    "                    out_block = (1-self.alpha)*in_feature + self.alpha*out_downsample\n",
    "                else:\n",
    "                    out_block = tf.layers.average_pooling2d(out_block, 2, 2)\n",
    "                    \n",
    "                in_block = out_block           \n",
    "            \n",
    "            # Output layer\n",
    "            out_add_std = tf.concat([out_block, mini_std], axis=-1)\n",
    "            \n",
    "            h2 = tf.layers.conv2d(out_add_std, filters=channel_list[-1], kernel_size=3, strides=1, \n",
    "                                  activation=tf.nn.leaky_relu, padding='SAME', name='h2')\n",
    "            h3 = tf.layers.conv2d(h2, filters=channel_list[-1], kernel_size=4, strides=4, \n",
    "                                  activation=tf.nn.leaky_relu, padding='SAME', name='h3')\n",
    "            \n",
    "            # Output layer\n",
    "            flatten = tf.reshape(h3, (-1, h3.get_shape()[3]))\n",
    "\n",
    "            logit  = tf.layers.dense(flatten, 1, name='logit_'+str(self.stage))\n",
    "            output = tf.sigmoid(logit)  \n",
    "\n",
    "        return logit, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "\n",
    "for i in range(len(size_list)):\n",
    "    model_list.append(PGGAN(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver = tf.train.Saver()\n",
    "\n",
    "if load_model == True:\n",
    "    Saver.restore(sess, load_path)\n",
    "    \n",
    "    if start_level != 0:\n",
    "        model_old = model_list[start_level-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    # Training\n",
    "    len_data = len(celebA_list)\n",
    "\n",
    "    for m in range(start_level, len(size_list)):\n",
    "        # Define models and set parameters for new level\n",
    "        model = model_list[m]\n",
    "        alpha = 0\n",
    "        count_step = 0\n",
    "        \n",
    "        batch_size = batch_list[m]\n",
    "        epoch = epoch_list[m]\n",
    "        \n",
    "        # Assign the parameters to the new layers\n",
    "        if m != 0:\n",
    "            model_var_d = model.trainable_vars_d\n",
    "            model_var_g = model.trainable_vars_g\n",
    "            \n",
    "            model_old_var_d = model_old.trainable_vars_d\n",
    "            model_old_var_g = model_old.trainable_vars_g\n",
    "            \n",
    "            for var_d in model_var_d:\n",
    "                var_d_split = var_d.name.split('/')\n",
    "                for var_old_d in model_old_var_d:\n",
    "                    var_old_d_split = var_old_d.name.split('/')\n",
    "                    \n",
    "                    if var_d_split[1] == var_old_d_split[1] and var_d_split[2] == var_old_d_split[2]:\n",
    "                        sess.run(var_d.assign(var_old_d))\n",
    "\n",
    "            for var_g in model_var_g:\n",
    "                var_g_split = var_g.name.split('/')\n",
    "                for var_old_g in model_old_var_g:\n",
    "                    var_old_g_split = var_old_g.name.split('/')\n",
    "                    \n",
    "                    if var_g_split[1] == var_old_g_split[1] and var_g_split[2] == var_old_g_split[2]:\n",
    "                        sess.run(var_g.assign(var_old_g))\n",
    "            \n",
    "            print('------------------- Var Assign is Finished! -------------------')\n",
    "        for i in range(epoch):\n",
    "            # Shuffle the data \n",
    "            np.random.shuffle(celebA_list)\n",
    "            \n",
    "            count_batch = 0\n",
    "            \n",
    "            # Making mini-batch\n",
    "            for j in range(0, len_data, batch_size):\n",
    "                # Get alpha for weighting the new layers \n",
    "                alpha = 1.2 * i/epoch + (1/epoch) * (j / len_data)\n",
    "                \n",
    "                if alpha > 1:\n",
    "                    alpha = 1.0\n",
    "                \n",
    "                if j + batch_size < len_data:\n",
    "                    x_in = np.zeros([batch_size, img_size, img_size, 3])\n",
    "\n",
    "                    for k in range(batch_size):\n",
    "                        img_temp = cv2.imread(celebA_list[j + k])\n",
    "                        x_in[k,:,:,:] = img_temp[45:45 + img_size, 25: 25+img_size, :]\n",
    "\n",
    "                x_in = x_in.reshape((-1, img_size, img_size, 3))\n",
    "                \n",
    "                x_in_resize = np.zeros([x_in.shape[0], size_list[m], size_list[m], 3])\n",
    "                \n",
    "                for k in range(x_in.shape[0]):\n",
    "                    x_in_resize[k,:,:,:] = resize(x_in[k,:,:,:], (size_list[m], size_list[m]))\n",
    "                \n",
    "                x_in_resize = np.float32(x_in_resize / 255.0)\n",
    "                \n",
    "                sampled_z = np.random.uniform(-1, 1, size=(x_in_resize.shape[0] , n_latent))              \n",
    "                \n",
    "                # Run Optimizer!\n",
    "                _, loss_d = sess.run([model.train_step_d, model.d_loss], feed_dict = {model.x: x_in_resize, \n",
    "                                                                                      model.z: sampled_z,\n",
    "                                                                                      model.alpha: [alpha],\n",
    "                                                                                      model.batch_size: batch_size})\n",
    "                \n",
    "                _, loss_g = sess.run([model.train_step_g, model.g_loss], feed_dict = {model.x: x_in_resize, \n",
    "                                                                                      model.z: sampled_z, \n",
    "                                                                                      model.alpha: [alpha],\n",
    "                                                                                      model.batch_size: batch_size})\n",
    "\n",
    "                print(\"Batch: {} / {}, Alpha: {}\".format(count_batch, int(len_data/batch_size), alpha), end=\"\\r\")\n",
    "                \n",
    "                count_batch += 1\n",
    "                \n",
    "                if count_step % show_result_step == 0 and count_step != 0:\n",
    "                    # Print Progess\n",
    "                    print(\"Epoch: {} / Batch: {:.3f}% / G Loss: {:.5f} / D Loss: {:.5f}\".format((i+1), (j/len_data), \n",
    "                                                                                                 loss_g, loss_d))\n",
    "\n",
    "                    # Show test images \n",
    "                    z_test = np.random.uniform(-1, 1, size=(5, n_latent))\n",
    "                    G_out = sess.run(model.G, feed_dict = {model.z:z_test, model.alpha:[alpha], model.batch_size:5})\n",
    "                    \n",
    "                    G_out = (G_out + 1.0)/2\n",
    "                    \n",
    "                    f1, ax1 = plt.subplots(1,5, figsize=(12,12))\n",
    "                    for k in range(5):\n",
    "                        img_RGB = cv2.cvtColor(x_in_resize[k,:,:,:], cv2.COLOR_BGR2RGB)\n",
    "                        ax1[k].imshow(img_RGB)\n",
    "                        ax1[k].axis('off')\n",
    "                        ax1[k].set_title('Sample '+str(k))\n",
    "\n",
    "                    f2, ax2 = plt.subplots(1,5, figsize=(12,12))\n",
    "                    for k in range(5):\n",
    "                        img_RGB = cv2.cvtColor(G_out[k,:,:,:], cv2.COLOR_BGR2RGB) \n",
    "                        ax2[k].imshow(img_RGB)\n",
    "                        ax2[k].axis('off')\n",
    "                        ax2[k].set_title('Image '+str(k))\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    count_step = 0\n",
    "\n",
    "                count_step+=1\n",
    "        \n",
    "        # Test Result of Each Level\n",
    "        num_test = 10\n",
    "\n",
    "        img = np.zeros([size_list[m] * num_test, size_list[m] * num_test, 3])\n",
    "\n",
    "        z_result = np.random.uniform(-1, 1, size=(num_test**2, n_latent))\n",
    "        G_result = sess.run(model.G, feed_dict = {model.z: z_result,  \n",
    "                                                  model.alpha: [1.0], model.batch_size: num_test**2})\n",
    "        G_result = (G_result + 1.0)/2\n",
    "        \n",
    "        for i in range(num_test**2):\n",
    "            row_num = int(i/num_test)\n",
    "            col_num = int(i%num_test)\n",
    "\n",
    "            img[row_num * size_list[m] : (row_num + 1) * size_list[m], \n",
    "                (col_num) * size_list[m] : (col_num + 1) * size_list[m]] = G_result[i,:,:,:]\n",
    "        \n",
    "        img_RGB = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2RGB) \n",
    "        \n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.imshow(img_RGB)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        #Save Model\n",
    "        os.mkdir(save_path)\n",
    "        os.mkdir(save_path + \"/\" + str(size_list[m]))\n",
    "        Saver.save(sess, save_path + \"/\" + str(size_list[m]) + \"/model\")\n",
    "        print(\"Model is saved in {}\".format(save_path + \"/\" + str(size_list[m]) + \"/model\"))\n",
    "\n",
    "        model_old = model\n",
    "        \n",
    "        print('\\n------------------ Level {} is DONE!! ------------------\\n'.format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Result of Each Level\n",
    "num_test = 10\n",
    "\n",
    "img = np.zeros([size_list[m] * num_test, size_list[m] * num_test, 3])\n",
    "\n",
    "z_result = np.random.uniform(-1, 1, size=(num_test**2, n_latent))\n",
    "G_result = sess.run(model.G, feed_dict = {model.z: z_result,  \n",
    "                                          model.alpha: [1.0], model.batch_size: num_test**2})\n",
    "G_result = (G_result + 1.0)/2\n",
    "\n",
    "for i in range(num_test**2):\n",
    "    row_num = int(i/num_test)\n",
    "    col_num = int(i%num_test)\n",
    "\n",
    "    img[row_num * size_list[m] : (row_num + 1) * size_list[m], \n",
    "        (col_num) * size_list[m] : (col_num + 1) * size_list[m]] = G_result[i,:,:,:]\n",
    "\n",
    "img_RGB = cv2.cvtColor(np.float32(img), cv2.COLOR_BGR2RGB) \n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(img_RGB)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
