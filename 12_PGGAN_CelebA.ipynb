{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGGAN CelebA\n",
    "\n",
    "This notebook is for implementing `Progressive Growing Generative Adversarial Network(PGGAN)` from the paper [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196) with [Tensorflow](https://www.tensorflow.org). <br>\n",
    "[CelebA dataset](https://www.kaggle.com/jessicali9530/celeba-dataset), which is 128x128 size, will be used. \n",
    "\n",
    "Reference: [hwalsuklee's Github](https://github.com/hwalsuklee/tensorflow-generative-model-collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import glob\n",
    "import cv2 \n",
    "import datetime\n",
    "import os\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'PGGAN_CelebA'\n",
    "\n",
    "img_size = 128\n",
    "\n",
    "n_latent = 512\n",
    "\n",
    "beta1 = 0\n",
    "beta2 = 0.99\n",
    "\n",
    "learning_rate_g = 0.00001\n",
    "learning_rate_d = 0.00001\n",
    "\n",
    "show_result_step = 100\n",
    "\n",
    "batch_list = [32, 32, 32, 16, 16, 16]\n",
    "epoch_list = [1, 2, 4, 8, 16, 32]\n",
    "size_list = [4, 8, 16, 32, 64, 128]\n",
    "channel_list = [64, 128, 256, 512, 512, 512]\n",
    "\n",
    "date_time = datetime.datetime.now().strftime(\"%Y%m%d-%H-%M-%S\")\n",
    "\n",
    "load_model = False\n",
    "train_model = True\n",
    "\n",
    "save_path = \"./saved_models/\" + date_time + \"_\" + algorithm\n",
    "load_path = \"./saved_models/20190809-11-04-47_PGGAN_CelebA/model/model\" \n",
    "\n",
    "# WGAN_GP Parateter\n",
    "n_critic = 1\n",
    "d_lambda = 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CelebA Dataset\n",
    "\n",
    "Get names of the files in the celeba dataset folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celebA_list = glob.glob('./img_align_celeba/*.jpg')\n",
    "\n",
    "print(\"CelebA dataset Length: {}\".format(len(celebA_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGGAN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGGAN():\n",
    "    def __init__(self, stage):\n",
    "        self.stage = stage\n",
    "        self.channel_list = channel_list\n",
    "        \n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, size_list[stage], size_list[stage], 3], name='x_'+str(stage))\n",
    "        self.x_normalize = (tf.cast(self.x, tf.float32) - (255.0/2)) / (255.0/2)\n",
    "\n",
    "        self.z = tf.placeholder(tf.float32, shape=[None, n_latent], name='z_'+str(stage))\n",
    "        \n",
    "        self.alpha = tf.placeholder(tf.float32, shape=[1])\n",
    "        self.batch_size = tf.placeholder(tf.float32)\n",
    "        \n",
    "        self.is_training = tf.placeholder(tf.bool, name='is_training_'+str(stage))\n",
    "\n",
    "        self.d_loss, self.g_loss, self.G = self.GAN(self.x_normalize, self.z, self.is_training) \n",
    "\n",
    "        # optimization\n",
    "        self.trainable_vars = tf.trainable_variables()\n",
    "\n",
    "        self.trainable_vars_d = [var for var in self.trainable_vars if var.name.startswith('Discriminator' + str(self.stage))]\n",
    "        self.trainable_vars_g = [var for var in self.trainable_vars if var.name.startswith('Generator' + str(self.stage))]\n",
    "        \n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer_d = tf.train.AdamOptimizer(learning_rate_d)\n",
    "            gvs_d = optimizer_d.compute_gradients(self.d_loss, var_list=self.trainable_vars_d)\n",
    "            capped_gvs_d = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs_d]\n",
    "            self.train_step_d = optimizer_d.apply_gradients(capped_gvs_d)\n",
    "            \n",
    "            optimizer_g = tf.train.AdamOptimizer(learning_rate_g)\n",
    "            gvs_g = optimizer_g.compute_gradients(self.g_loss, var_list=self.trainable_vars_g)\n",
    "            capped_gvs_g = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gvs_g]\n",
    "            self.train_step_g = optimizer_g.apply_gradients(capped_gvs_g)\n",
    "\n",
    "    def GAN(self, x, z, is_training):\n",
    "        # Generator\n",
    "        G, mini_std = self.Generator(z, is_training)\n",
    "\n",
    "        # Discriminator\n",
    "        D_logit_real, D_out_real = self.Discriminator(x, mini_std, is_training)\n",
    "        D_logit_fake, D_out_fake = self.Discriminator(G, mini_std, is_training, reuse=True)\n",
    "\n",
    "        # get loss \n",
    "        ########################################### WGAN GP ###########################################\n",
    "        eps = tf.random_uniform(shape=tf.shape(x),minval=0.0, maxval=1.0)       \n",
    "        x_hat = (eps * x) + ((1-eps) * G)\n",
    "        D_hat, _ = self.Discriminator(x_hat, mini_std, is_training, reuse=True)\n",
    "        grad = tf.gradients(D_hat, [x_hat])[0]\n",
    "        GP = d_lambda * tf.square(tf.norm(grad, ord=2) - 1)\n",
    "\n",
    "        d_loss = -tf.reduce_mean(D_logit_real) + tf.reduce_mean(D_logit_fake) + GP # + 0.001*tf.reduce_mean(tf.square(D_logit_real))\n",
    "        g_loss = -tf.reduce_mean(D_logit_fake) \n",
    "        ###############################################################################################\n",
    "    \n",
    "        return d_loss, g_loss , G\n",
    "    \n",
    "    # Pixel Normalization\n",
    "    def pixel_norm(self, x, epsilon=1e-8):\n",
    "        return x * tf.rsqrt(tf.reduce_mean(tf.square(x), axis=-1, keepdims=True) + epsilon)\n",
    "    \n",
    "    # Minibatch Standard Deviation\n",
    "    def minibatch_std(self, x):\n",
    "        # Compute Standard Deviation over minibatch\n",
    "        _, batch_std = tf.nn.moments(x, axes=[0], keep_dims=True)\n",
    "        \n",
    "        # Average all features\n",
    "        feature_avg = tf.reduce_mean(batch_std, axis=-1, keepdims=True)\n",
    "        \n",
    "        # Replicate the value to concatenate it over the minibatch\n",
    "        out = tf.tile(feature_avg, multiples=[self.batch_size, 1, 1, 1])\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def conv_block_g(self, x, num_channel, network_name):\n",
    "#         h_enc = tf.layers.conv2d(x, filters=num_channel, kernel_size=1, strides=1, padding='SAME', name=network_name+'_enc')\n",
    "        \n",
    "        h1 = tf.layers.conv2d(x, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_1')\n",
    "        h1 = tf.nn.leaky_relu(self.pixel_norm(h1))  \n",
    "            \n",
    "        h2 = tf.layers.conv2d(h1, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_2')\n",
    "        h2 = tf.nn.leaky_relu(self.pixel_norm(h2))  \n",
    "            \n",
    "#         h3 = tf.layers.conv2d(h2, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_3')\n",
    "#         h3 = tf.nn.leaky_relu(self.pixel_norm(h3) + self.pixel_norm(h_enc))\n",
    "#         h3 = tf.nn.leaky_relu(self.pixel_norm(h3))\n",
    "\n",
    "#         h4 = tf.layers.conv2d(h3, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_4')\n",
    "#         h4 = tf.nn.leaky_relu(self.pixel_norm(h4) + h_enc)  \n",
    "        \n",
    "        return h2\n",
    "\n",
    "    \n",
    "    def conv_block_d(self, x, num_channel, network_name):\n",
    "        h1 = tf.layers.conv2d(x, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_1')\n",
    "        h1 = tf.nn.leaky_relu(h1)\n",
    "        \n",
    "        h2 = tf.layers.conv2d(h1, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_2')\n",
    "        h2 = tf.nn.leaky_relu(h2)\n",
    "        \n",
    "#         h3 = tf.layers.conv2d(h2, filters=num_channel, kernel_size=3, strides=1, padding='SAME', name=network_name+'_3')\n",
    "#         h3 = tf.nn.leaky_relu(h3)\n",
    "           \n",
    "        return h2\n",
    "\n",
    "    def Generator(self, x, is_training, reuse=False):\n",
    "        with tf.variable_scope('Generator' + str(self.stage), reuse=reuse):       \n",
    "            # Project and Reshape \n",
    "            z_size = int(size_list[0]/4)\n",
    "            \n",
    "            x_project = tf.layers.dense(x, z_size*z_size*n_latent)\n",
    "            x_reshape = tf.reshape(x_project, (-1, z_size, z_size, n_latent))\n",
    "            \n",
    "            h1 = tf.layers.conv2d_transpose(x_reshape,filters=channel_list[-1], kernel_size=4, strides=4, padding='SAME')\n",
    "            h1 = tf.nn.leaky_relu(self.pixel_norm(h1))\n",
    "            \n",
    "            h2 = tf.layers.conv2d(h1,filters=channel_list[-1], kernel_size=3, strides=1, padding='SAME')\n",
    "            h2 = tf.nn.leaky_relu(self.pixel_norm(h2))  \n",
    "\n",
    "            h3 = tf.layers.conv2d(h2,filters=channel_list[-1], kernel_size=3, strides=1, padding='SAME')\n",
    "            h3 = tf.nn.leaky_relu(self.pixel_norm(h3))\n",
    "\n",
    "            mini_std = self.minibatch_std(h3)\n",
    "        \n",
    "            in_block = h3\n",
    "            out_block = h3\n",
    "            upsample = h3\n",
    "\n",
    "            for i in range(self.stage):\n",
    "                upsample = tf.image.resize_nearest_neighbor(in_block, (size_list[i+1], size_list[i+1]))\n",
    "                out_block = self.conv_block_g(upsample, channel_list[-2-i], 'block'+str(i))\n",
    "                in_block = out_block\n",
    "\n",
    "            # Output layer           \n",
    "            RGB1 = tf.layers.conv2d(upsample, filters=3, kernel_size=1, strides=1, padding='SAME', name='RGB1_'+str(self.stage)) \n",
    "            RGB2 = tf.layers.conv2d(out_block, filters=3, kernel_size=1, strides=1, padding='SAME', name='RGB2_'+str(self.stage)) \n",
    "            \n",
    "            logits = (1-self.alpha)*RGB1 + self.alpha*RGB2\n",
    "            \n",
    "            output = tf.tanh(logits)\n",
    "        \n",
    "        return output, mini_std      \n",
    "\n",
    "\n",
    "    def Discriminator(self, x, mini_std, is_training, reuse=False):\n",
    "        with tf.variable_scope('Discriminator' + str(self.stage), reuse=reuse):\n",
    "            \n",
    "            h1 = tf.layers.conv2d(x, filters=channel_list[-self.stage-1], kernel_size=1, strides=1, activation=tf.nn.leaky_relu, \n",
    "                      padding='SAME', name='h1_'+str(self.stage))\n",
    "                \n",
    "            in_block = h1\n",
    "            out_block = h1\n",
    "            \n",
    "            for i in range(self.stage):\n",
    "                out_block = self.conv_block_d(in_block, channel_list[-self.stage+i], 'block'+str(self.stage-1-i))\n",
    "                \n",
    "                if i == 0:\n",
    "                    out_downsample = tf.layers.average_pooling2d(out_block, 2, 2)\n",
    "                    in_downsample = tf.layers.average_pooling2d(in_block, 2, 2)\n",
    "                    in_feature = tf.layers.conv2d(in_downsample, filters=out_downsample.get_shape()[3], \n",
    "                                                  kernel_size=1, strides=1, padding='SAME', name='feature_'+str(self.stage))\n",
    "                    out_block = (1-self.alpha)*in_feature + self.alpha*out_downsample\n",
    "                else:\n",
    "                    out_block = tf.layers.average_pooling2d(out_block, 2, 2)\n",
    "                    \n",
    "                in_block = out_block           \n",
    "            \n",
    "            # Output layer\n",
    "            out_add_std = tf.concat([out_block, mini_std], axis=-1)\n",
    "            \n",
    "            h2 = tf.layers.conv2d(out_add_std, filters=64, kernel_size=3, strides=1, \n",
    "                                  activation=tf.nn.leaky_relu, padding='SAME', name='h2')\n",
    "            h3 = tf.layers.conv2d(h2, filters=64, kernel_size=4, strides=4, \n",
    "                                  activation=tf.nn.leaky_relu, padding='SAME', name='h3')\n",
    "            \n",
    "            # Output layer\n",
    "            flatten = tf.reshape(h3, (-1, h3.get_shape()[3]))\n",
    "\n",
    "            logit  = tf.layers.dense(flatten, 1, name='logit_'+str(self.stage))\n",
    "            output = tf.sigmoid(logit)  \n",
    "\n",
    "        return logit, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "\n",
    "for i in range(len(size_list)):\n",
    "    model_list.append(PGGAN(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Saver = tf.train.Saver()\n",
    "\n",
    "if load_model == True:\n",
    "    Saver.restore(sess, load_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    # Training\n",
    "    len_data = len(celebA_list)\n",
    "\n",
    "    for m in range(len(size_list)):\n",
    "        # Define models and set parameters for new level\n",
    "        model = model_list[m]\n",
    "        alpha = 0\n",
    "        count_step = 0\n",
    "        \n",
    "        batch_size = batch_list[m]\n",
    "        epoch = epoch_list[m]\n",
    "        \n",
    "        # Assign the parameters to the new layers\n",
    "        if m != 0:\n",
    "            model_var_d = model.trainable_vars_d\n",
    "            model_var_g = model.trainable_vars_g\n",
    "            \n",
    "            model_old_var_d = model_old.trainable_vars_d\n",
    "            model_old_var_g = model_old.trainable_vars_g\n",
    "            \n",
    "            for var_d in model_var_d:\n",
    "                var_d_split = var_d.name.split('/')\n",
    "                for var_old_d in model_old_var_d:\n",
    "                    var_old_d_split = var_old_d.name.split('/')\n",
    "                    \n",
    "                    if var_d_split[1] == var_old_d_split[1] and var_d_split[2] == var_old_d_split[2]:\n",
    "                        sess.run(var_old_d.assign(var_d))\n",
    "\n",
    "            for var_g in model_var_g:\n",
    "                var_g_split = var_g.name.split('/')\n",
    "                for var_old_g in model_old_var_g:\n",
    "                    var_old_g_split = var_old_g.name.split('/')\n",
    "                    \n",
    "                    if var_g_split[1] == var_old_g_split[1] and var_g_split[2] == var_old_g_split[2]:\n",
    "                        sess.run(var_old_g.assign(var_g))\n",
    "            \n",
    "            print('------------------- Var Assign is Finished! -------------------')\n",
    "        for i in range(epoch):\n",
    "            # Shuffle the data \n",
    "            np.random.shuffle(celebA_list)\n",
    "            \n",
    "            count_batch = 0\n",
    "            # Get alpha for weighting the new layers \n",
    "#             alpha = 1.2*np.exp(i/epoch)-1\n",
    "#             alpha = 1.2*i/epoch\n",
    "\n",
    "#             if alpha > 1:\n",
    "#                 alpha = 1.0\n",
    "            \n",
    "            # Making mini-batch\n",
    "            for j in range(0, len_data, batch_size):\n",
    "                alpha = 1.2* i/epoch + (1/epoch) * (j / len_data)\n",
    "                \n",
    "                if alpha > 1:\n",
    "                    alpha = 1.0\n",
    "                \n",
    "                if j + batch_size < len_data:\n",
    "                    x_in = np.zeros([batch_size, img_size, img_size, 3])\n",
    "\n",
    "                    for k in range(batch_size):\n",
    "                        img_temp = cv2.imread(celebA_list[j + k])\n",
    "                        x_in[k,:,:,:] = img_temp[45:45 + img_size, 25: 25+img_size, :]\n",
    "\n",
    "                x_in = x_in.reshape((-1, img_size, img_size, 3))\n",
    "                \n",
    "                x_in_resize = np.zeros([x_in.shape[0], size_list[m], size_list[m], 3])\n",
    "                \n",
    "                for k in range(x_in.shape[0]):\n",
    "                    x_in_resize[k,:,:,:] = resize(x_in[k,:,:,:], (size_list[m], size_list[m]))\n",
    "                    \n",
    "                sampled_z = np.random.uniform(-1, 1, size=(x_in_resize.shape[0] , n_latent))              \n",
    "                \n",
    "                # Run Optimizer!\n",
    "                _, loss_d = sess.run([model.train_step_d, model.d_loss], feed_dict = {model.x: x_in_resize, \n",
    "                                                                                      model.z: sampled_z,\n",
    "                                                                                      model.is_training: True,\n",
    "                                                                                      model.alpha: [alpha],\n",
    "                                                                                      model.batch_size: batch_size})\n",
    "                _, loss_g = sess.run([model.train_step_g, model.g_loss], feed_dict = {model.x: x_in_resize, \n",
    "                                                                                      model.z: sampled_z, \n",
    "                                                                                      model.is_training: True,\n",
    "                                                                                      model.alpha: [alpha],\n",
    "                                                                                      model.batch_size: batch_size})\n",
    "\n",
    "                print(\"Batch: {} / {}, Alpha: {}\".format(count_batch, int(len_data/batch_size), alpha), end=\"\\r\")\n",
    "                \n",
    "                count_batch += 1\n",
    "                \n",
    "                if count_step % show_result_step == 0:\n",
    "                    # Print Progess\n",
    "                    print(\"Epoch: {} / Batch: {:.3f}% / G Loss: {:.5f} / D Loss: {:.5f}\".format((i+1), (j/len_data), \n",
    "                                                                                                 loss_g, loss_d))\n",
    "\n",
    "                    # Show test images \n",
    "                    z_test = np.random.uniform(-1, 1, size=(5, n_latent))\n",
    "                    G_out = sess.run(model.G, feed_dict = {model.z: z_test, model.is_training: False, \n",
    "                                                           model.alpha: [alpha], model.batch_size: 5})\n",
    "                    x_in_resize = np.float32(x_in_resize / 255.0)\n",
    "                    G_out = (G_out + 1.0)/2\n",
    "                    \n",
    "                    f1, ax1 = plt.subplots(1,5)\n",
    "                    for k in range(5):\n",
    "                        img_RGB = cv2.cvtColor(x_in_resize[k,:,:,:], cv2.COLOR_BGR2RGB)\n",
    "                        ax1[k].imshow(img_RGB)\n",
    "                        ax1[k].axis('off')\n",
    "                        ax1[k].set_title('Sample '+str(k))\n",
    "\n",
    "                    f2, ax2 = plt.subplots(1,5)\n",
    "                    for k in range(5):\n",
    "                        img_RGB = cv2.cvtColor(G_out[k,:,:,:], cv2.COLOR_BGR2RGB) \n",
    "                        ax2[k].imshow(img_RGB)\n",
    "                        ax2[k].axis('off')\n",
    "                        ax2[k].set_title('Image '+str(k))\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    count_step = 0\n",
    "\n",
    "                count_step+=1\n",
    "        \n",
    "        # Test Result of Each Level\n",
    "        num_test = 10\n",
    "\n",
    "        img = np.zeros([size_list[m] * num_test, size_list[m] * num_test, 3])\n",
    "\n",
    "        z_result = np.random.uniform(-1, 1, size=(num_test**2, n_latent))\n",
    "        G_result = sess.run(model.G, feed_dict = {model.z: z_result, model.is_training: False, \n",
    "                                                  model.alpha: [1.0], model.batch_size: num_test**2})\n",
    "        G_result = (G_result + 1.0)/2\n",
    "        \n",
    "        for i in range(num_test**2):\n",
    "            row_num = int(i/num_test)\n",
    "            col_num = int(i%num_test)\n",
    "\n",
    "            img[row_num * size_list[m] : (row_num + 1) * size_list[m], \n",
    "                (col_num) * size_list[m] : (col_num + 1) * size_list[m]] = G_result[i,:,:,:]\n",
    "\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        model_old = model\n",
    "        \n",
    "        print('\\n------------------ Level {} is DONE!! ------------------\\n'.format(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_result, x_result_norm = sess.run([model.x, model.x_normalize], feed_dict = {model.x: x_in_resize, \n",
    "                                                                                      model.z: sampled_z,\n",
    "                                                                                      model.is_training: True,\n",
    "                                                                                      model.alpha: [alpha],\n",
    "                                                                                      model.batch_size: batch_size})\n",
    "\n",
    "print(np.max(x_result))\n",
    "print(np.min(x_result))\n",
    "print(x_result.shape)\n",
    "print(type(x_result[0,0,0,0]))\n",
    "\n",
    "print(np.max(x_result_norm))\n",
    "print(np.min(x_result_norm))\n",
    "print(x_result_norm.shape)\n",
    "print(type(x_result_norm[0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_out.shape)\n",
    "print(np.max(G_out))\n",
    "print(np.min(G_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test = 10\n",
    "\n",
    "img = np.zeros([size_list[-1] * num_test, size_list[-1] * num_test])\n",
    "\n",
    "z_result = np.random.uniform(-1, 1, size=(num_test**2, n_latent))\n",
    "G_result = sess.run(model.G, feed_dict = {z: z_result})\n",
    "\n",
    "for i in range(num_test**2):\n",
    "    row_num = int(i/num_test)\n",
    "    col_num = int(i%num_test)\n",
    "    \n",
    "    img[row_num * img_size : (row_num + 1) * img_size, (col_num) * img_size : (col_num + 1) * img_size] = G_result[i,:,:,0]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(save_path)\n",
    "\n",
    "Saver.save(sess, save_path + \"/model/model\")\n",
    "print(\"Model is saved in {}\".format(save_path + \"/model/model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
